{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification MNIST using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device: GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),                      \n",
    "     transforms.Normalize((0.5, ), (0.5, ))])    \n",
    "\n",
    "trainval_dataset = datasets.MNIST(root='./data', \n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transform)\n",
    "train_size = int(0.8 * len(trainval_dataset))\n",
    "val_size = int(len(trainval_dataset)-train_size)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(trainval_dataset, [train_size, val_size])\n",
    "test_dataset = datasets.MNIST(root='./data', \n",
    "                                        train=False, \n",
    "                                        download=True, \n",
    "                                        transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Detaloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False)\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader, \"test\": test_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        self.seq_len = 28\n",
    "        self.feature_size = 28\n",
    "        self.hidden_layer_size = 128\n",
    "        self.lstm_layers = 5\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.feature_size, \n",
    "                            self.hidden_layer_size, \n",
    "                            num_layers = self.lstm_layers)\n",
    "        \n",
    "        self.fc = nn.Linear(self.hidden_layer_size, 10)\n",
    "        \n",
    "    def init_hidden_cell(self, batch_size):\n",
    "        hedden = torch.zeros(self.lstm_layers, batch_size, self.hidden_layer_size).to(device)\n",
    "        cell = torch.zeros(self.lstm_layers, batch_size, self.hidden_layer_size).to(device)        \n",
    "        return (hedden, cell)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        self.hidden_cell = self.init_hidden_cell(batch_size)\n",
    "        x = x.view(batch_size, self.seq_len, self.feature_size)  # (Batch, Cannel, Height, Width) -> (Batch, Height, Width) = (Batch, Seqence, Feature)\n",
    "        x = x.permute(1, 0, 2)                                   # (Batch, Seqence, Feature) -> (Seqence , Batch, Feature)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x, self.hidden_cell)    # LSTM input: (Seqence, Batch, Feature)\n",
    "                                                                 # h_n Shape: (num_layers, batch, hidden_size)\n",
    "        x = h_n[-1,:,:]\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss Function & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, dataloaders_dict, criterion, optimizer, device, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval() \n",
    "\n",
    "            epoch_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "\n",
    "            if (epoch == 0) and (phase == 'train'):\n",
    "                continue\n",
    "\n",
    "            for i , (inputs, labels) in tqdm(enumerate(dataloaders_dict[phase])):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    epoch_loss += loss.item() * inputs.size(0)  \n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 39.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:02, 41.93it/s]\n",
      "3it [00:00, 29.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 2.3057 Acc: 0.0983\n",
      "Epoch 2/10\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375it [00:13, 28.05it/s]\n",
      "5it [00:00, 41.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7195 Acc: 0.7496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:02, 44.91it/s]\n",
      "4it [00:00, 31.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2187 Acc: 0.9376\n",
      "Epoch 3/10\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375it [00:12, 29.04it/s]\n",
      "4it [00:00, 31.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1501 Acc: 0.9550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:02, 39.69it/s]\n",
      "4it [00:00, 31.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1175 Acc: 0.9647\n",
      "Epoch 4/10\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375it [00:12, 30.49it/s]\n",
      "4it [00:00, 39.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0922 Acc: 0.9728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:02, 43.62it/s]\n",
      "4it [00:00, 30.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1003 Acc: 0.9720\n",
      "Epoch 5/10\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375it [00:12, 29.69it/s]\n",
      "5it [00:00, 42.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0712 Acc: 0.9789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:02, 44.15it/s]\n",
      "4it [00:00, 31.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0861 Acc: 0.9743\n",
      "Epoch 6/10\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375it [00:12, 30.14it/s]\n",
      "5it [00:00, 42.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0554 Acc: 0.9834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:02, 40.18it/s]\n",
      "4it [00:00, 32.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0769 Acc: 0.9759\n",
      "Epoch 7/10\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375it [00:11, 31.62it/s]\n",
      "4it [00:00, 32.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0507 Acc: 0.9852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:02, 42.32it/s]\n",
      "4it [00:00, 32.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0663 Acc: 0.9806\n",
      "Epoch 8/10\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375it [00:12, 29.33it/s]\n",
      "5it [00:00, 42.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0448 Acc: 0.9864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:02, 43.21it/s]\n",
      "4it [00:00, 31.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0637 Acc: 0.9811\n",
      "Epoch 9/10\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375it [00:13, 28.61it/s]\n",
      "5it [00:00, 44.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0384 Acc: 0.9883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:02, 42.01it/s]\n",
      "4it [00:00, 31.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0512 Acc: 0.9849\n",
      "Epoch 10/10\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375it [00:12, 29.71it/s]\n",
      "5it [00:00, 44.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0314 Acc: 0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:02, 43.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0623 Acc: 0.9829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = train_model(net, dataloaders_dict, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_iterator = iter(dataloaders_dict[\"test\"])\n",
    "imges, labels = next(batch_iterator)\n",
    "\n",
    "net.eval()\n",
    "with torch.set_grad_enabled(False):\n",
    "    outputs = net(imges.to(device))\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "plt.imshow(imges[0].numpy().reshape(28,28), cmap='gray')\n",
    "plt.title(\"Label: Target={}, Predict={}\".format(labels[0], preds[0]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
